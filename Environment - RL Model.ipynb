{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Failed to import scipy.linalg.blas, and Theano flag blas.ldflags is empty. Falling back on slower implementations for dot(matrix, vector), dot(vector, matrix) and dot(vector, vector) (DLL load failed: %1 is not a valid Win32 application.)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from game_functions.environment import sbfeatures as sbf\n",
    "from game_functions.model import brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n"
     ]
    }
   ],
   "source": [
    "# initalize environment\n",
    "env = sbf.Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize controller\n",
    "env.controller(initialize=True, close=True)\n",
    "env.controller(initialize=True, opens=True)\n",
    "env.action(5, delay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launching game...\n"
     ]
    }
   ],
   "source": [
    "# launch game\n",
    "env.make()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start game from menu\n",
    "env.start_game(botsOn=True, mode='easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hwnd: 12454096\n",
      "pid: c_long(8604)\n"
     ]
    }
   ],
   "source": [
    "# attached onto game memory\n",
    "env.initalize_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9, -4.5, -10.1, -5.7, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# test observation\n",
    "print(env.observation())\n",
    "#env.__grab_addresses__()\n",
    "#env.__grab_features__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "# test observation\n",
    "print(env.p1_score, env.p2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward structure defined!\n"
     ]
    }
   ],
   "source": [
    "# setup reward structure\n",
    "env.reward_structure(p1_death=-1, p2_death=1, p1_damage=-0.01, p2_damage=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test reward calculation between states\n",
    "print(env.reward(stale_observation=env.features, new_observation=env.observation()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test controller input\n",
    "env.action(5, delay=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = 17\n",
    "\n",
    "\n",
    "Qas = brain.keras_model(inputs=input_shape, dropouts=0.2, opti=1e-6, clipping=1, clipval=10)\n",
    "Qas.load_weights('model_weights//kill_rewards_TD5_LA_LRELU//1500000_model_backup_20170628_0818.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0 0\n",
      "0 0 0\n",
      "7 0 0\n",
      "7 0 0\n",
      "0 0 0\n",
      "3 0 0\n",
      "7 0 0\n",
      "7 0 0\n",
      "0 0 0\n",
      "7 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "4 0 0\n",
      "4 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n",
      "0 0 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1770d4f4bde3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp1_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp2_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[1;31m#datapoint.append(action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jimmy\\Desktop\\memorpy\\SBbot\\game_functions\\environment\\sbfeatures.py\u001b[0m in \u001b[0;36maction\u001b[0;34m(self, move, delay)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mpb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0mdelay\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelay\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mvj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmvx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmvy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmove\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Jimmy\\Desktop\\memorpy\\SBbot\\game_functions\\controller\\vjoy_controller.py\u001b[0m in \u001b[0;36maim\u001b[0;34m(self, x, y, button, defaultbutton, delay)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdefaultbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendJoystick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbutton\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msendJoystick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdefaultbutton\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "episode = 0\n",
    "training_backup = 500000\n",
    "save_location = \"training_data\\\\\"\n",
    "training_batch = []\n",
    "\n",
    "# action settings\n",
    "randomness = True\n",
    "\n",
    "#score keeping\n",
    "p1_score = 0\n",
    "p2_score = 0\n",
    "\n",
    "#init#\n",
    "prev_observation = env.observation()[:]\n",
    "observation = env.observation()[:]\n",
    "header = ['episode','p1h', 'p1_x',' p1_y', 'p2h', 'p2_x',' p2_y',\n",
    "          'right_of', 'left_of', 'above', 'below', 'x_clear', 'y_clear',\n",
    "          'cd1', 'cd2',\n",
    "         'aim_down', 'aim_left', 'aim_up', 'aim_right',\n",
    "         'p1_x_delta', 'p2_x_delta', 'p1_y_delta', 'p2_y_delta',\n",
    "         'action', 'reward', 'p1_score', 'p2_score']\n",
    "\n",
    "while True:\n",
    "\n",
    "        episode += 1\n",
    "        \n",
    "        #random action\n",
    "        if randomness:\n",
    "            action = random.randint(0, 7)\n",
    "\n",
    "        #env.action(action, delay=0.1)\n",
    "        \n",
    "        observation = env.observation()[:]\n",
    "        reward = env.reward(stale_observation=prev_observation, \n",
    "                            new_observation=observation)\n",
    "        prev_observation = observation\n",
    "        \n",
    "        #datapoint = [episode]\n",
    "        datapoint = []\n",
    "        datapoint.extend(observation)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        predictions = env.create_predictions(datapoint)\n",
    "        action_rewards = Qas.predict(predictions)\n",
    "        \n",
    "        #---action = np.where(advantage == np.amax(advantage))[0][0]\n",
    "        action = np.where(action_rewards == np.amax(action_rewards))[0][0] # greedy action\n",
    "        print(action, env.p1_score, env.p2_score)\n",
    "        \n",
    "        env.action(action, delay=0.1)\n",
    "        \n",
    "        #datapoint.append(action)\n",
    "        #datapoint.append(reward)\n",
    "        #datapoint.extend([env.p1_score + 25000, env.p2_score + 25000])\n",
    "\n",
    "        training_batch.append(datapoint)\n",
    "        \n",
    "        if (len(training_batch) % training_backup) == 0:\n",
    "            name =  save_location + str(episode) + '_training_backup_' + datetime.datetime.today().strftime('%Y%m%d_%H%M') + '.csv'\n",
    "            exp = pd.DataFrame(training_batch)\n",
    "            exp.columns = header\n",
    "            exp.to_csv(name, index=False)\n",
    "            print('Saving Training Experience...')\n",
    "            training_batch = []\n",
    "    \n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35_32]",
   "language": "python",
   "name": "conda-env-py35_32-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
